{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d652b8c-b5e3-4acc-a437-c8880f8bc0e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the necessary libraries\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "51650493-640f-4570-aa31-a8abcf25b047",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a function to load in each maze\n",
    "def load_image(num):\n",
    "    image = cv2.imread(\"[local path to maze files]\" + num + \".png\") # Loading the image\n",
    "    image = image[:,:,0]+image[:,:,1]+image[:,:,2] # Summing the layers\n",
    "\n",
    "    # Creating the maze array to read the image\n",
    "    maze_array  = np.zeros((21,21))\n",
    "\n",
    "    # Reducing an image array down to a maze state array\n",
    "    for i in range(len(maze_array)):\n",
    "        for j in range(len(maze_array)):\n",
    "            if image[0+i*20+1,0+j*20+1] == 0.0:\n",
    "                maze_array[i,j] = 0.0\n",
    "            else:\n",
    "                maze_array[i,j] = 253.0\n",
    "\n",
    "    # Differentiating the starting and ending points\n",
    "    maze_array[1,0] = 30.0\n",
    "    maze_array[19,20] = 120.0\n",
    "\n",
    "    return maze_array,1,0,reward_matrix()\n",
    "\n",
    "# Creating the reward distribution\n",
    "def reward_matrix():\n",
    "\n",
    "    # Setting the reward scaling factor\n",
    "    scale = 40\n",
    "\n",
    "    # filling the array using radial distance (rounded)\n",
    "    rewards = np.zeros((21,21))\n",
    "    for i in range(len(rewards)):\n",
    "        for j in range(len(rewards)):\n",
    "            rewards[i,j] = scale-round(np.sqrt((19-i)**2+(19-j)**2))\n",
    "    \n",
    "    return rewards\n",
    "\n",
    "# Given a maze state and position, scanning for possible actions\n",
    "def compute_actions(state,row,col):\n",
    "    actions = []\n",
    "    if state[row+1,col] != 0 and state[row+1,col] != 30 and state[row+1,col] != 120 and state[row+1,col] != 200:\n",
    "        actions.append(\"down\")\n",
    "    if state[row-1,col] != 0 and state[row-1,col] != 30 and state[row-1,col] != 120 and state[row-1,col] != 200:\n",
    "        actions.append(\"up\")\n",
    "    if state[row,col+1] != 0 and state[row,col+1] != 30 and state[row,col+1] != 120 and state[row,col+1] != 200:\n",
    "        actions.append(\"right\")\n",
    "    if state[row,col-1] != 0 and state[row,col-1] != 30 and state[row,col-1] != 120 and state[row,col-1] != 200:\n",
    "        actions.append(\"left\")\n",
    "    return actions\n",
    "\n",
    "# After selecting a state, proceeding in the direction and updating the maze state\n",
    "def take_step(state,action,row,col):\n",
    "    state[row,col] = 30\n",
    "    if action == \"right\":\n",
    "        state[row,col+1] = 200\n",
    "        return state,row,col+1\n",
    "    if action == \"left\":\n",
    "        state[row,col-1] = 200\n",
    "        return state,row,col-1\n",
    "    if action == \"up\":\n",
    "        state[row-1,col] = 200\n",
    "        return state,row-1,col\n",
    "    if action == \"down\":\n",
    "        state[row+1,col] = 200\n",
    "        return state,row+1,col\n",
    "\n",
    "# Creating a function to repeatedly wander a branch using Monte Carlo simulation\n",
    "def random_wander(state,row,col,rewards):\n",
    "\n",
    "    # Setting an intial reward value\n",
    "    reward = 0\n",
    "\n",
    "    # Testing the random path seeking (as many as 15 steps ahead)\n",
    "    for i in range(15):\n",
    "        # Listing possible actions\n",
    "        actions = compute_actions(state,row,col)\n",
    "\n",
    "        # Checking if the route meets the exit\n",
    "        if row == 19 and col == 19:\n",
    "            # Providing a decisive reward\n",
    "            reward += 10000\n",
    "            # Ending the path\n",
    "            break\n",
    "            \n",
    "        # Testing if you've hit a dead end\n",
    "        if len(actions) == 0:\n",
    "            state[row,col] = 200\n",
    "            # Ending the path\n",
    "            break\n",
    "        else:\n",
    "            # Choosing a random traversal direction\n",
    "            state, row, col = take_step(state,random.choice(actions),row,col)\n",
    "        reward += rewards[row,col]\n",
    "\n",
    "    return round(reward)\n",
    "\n",
    "# Creating a method to evaluate each possible action at an intersection\n",
    "def test_actions(state, actions, row, col,rewards_array):\n",
    "    # Creating a list to store the average reward down each path\n",
    "    rewards = []\n",
    "\n",
    "    # Duplicating the state for each possible action\n",
    "    for path in actions:\n",
    "        temp_rewards = []\n",
    "        temp_copy = np.copy(state)\n",
    "        # Taking the action\n",
    "        temp_copy, temp_row, temp_col = take_step(temp_copy, path, row, col)\n",
    "\n",
    "        # Proceeding down 100 random paths along a gievn branch\n",
    "        for i in range(100):  \n",
    "            reward = random_wander(np.copy(temp_copy), temp_row, temp_col,rewards_array)\n",
    "            temp_rewards.append(reward)\n",
    "        \n",
    "        # rewards.append(np.max(temp_rewards)) # Returning the maximum reward\n",
    "        rewards.append(np.mean(temp_rewards)) # Returning the average reward\n",
    "\n",
    "    # Returning the index of the \"best\" action\n",
    "    return rewards.index(max(rewards))\n",
    "\n",
    "# Creating a method to solve a given puzzle\n",
    "def solve_puzzle(state,row,col,rewards):\n",
    "    # Allows for up to 1500 episodes (no path length restrictions)\n",
    "    for i in range(1500):\n",
    "\n",
    "        # If the agent has reached the end, end the loop\n",
    "        if row == 19 and col == 19:\n",
    "            return 1\n",
    "            break\n",
    "    \n",
    "        # Finding the possible actions in the current state\n",
    "        actions = compute_actions(state,row,col)\n",
    "        # Showing failure if stuck in dead end\n",
    "        if len(actions) == 0:\n",
    "            return 0\n",
    "            break\n",
    "        # Following a path if not at intersection\n",
    "        if len(actions) == 1:\n",
    "            state, row, col = take_step(state,actions[0],row,col)\n",
    "        # If at intersection, using Monte Carlo simulation to decide path\n",
    "        else:\n",
    "            act = test_actions(state,actions,row,col,rewards)\n",
    "            state, row, col = take_step(state,actions[act],row,col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "57607e35-f15c-49c0-8885-251da01667ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.427\n"
     ]
    }
   ],
   "source": [
    "# Using a counter to track successful solutions\n",
    "correct = 0\n",
    "\n",
    "# Iterating through solving each puzzle\n",
    "for puzzle in range(1000):\n",
    "    state, row, col, rewards = load_image(str(puzzle))\n",
    "    correct += solve_puzzle(state,row,col,rewards)\n",
    "\n",
    "# Displaying the algorithm's accuracy\n",
    "print(correct/1000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
